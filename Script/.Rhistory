colTypes = sapply(1:ncol(total), function(i) class(total[,i]))
table(colTypes)
total_factors = total[, colTypes == "factor"]
head(total_factors)
train = read.csv("../Data/train_new.csv", stringsAsFactors = T)
test = read.csv("../Data/test_new.csv", stringsAsFactors = T)
rownames(train) = train$id
rownames(test) = test$id
train = train[,-1]
test = test[,-1]
train_price = train[,ncol(train)]
macro = read.csv("../Data/macro_impute.csv")
total = rbind(train[,-ncol(train)], test)
total = merge(total, macro, by = "timestamp")
head(total[,c("timestamp", "x")])
colnames(total)
head(total[,c("timestamp", "X")])
macro[1:5,1:5]
macro = read.csv("../Data/macro_impute.csv")
total = rbind(train[,-ncol(train)], test)
total = merge(total, macro, by = "timestamp")
dim(total)
total = rbind(train[,-ncol(train)], test)
dim(total)
macro = read.csv("../Data/macro_impute.csv")
macro[1:5,1:5]
load("C:/XIANGGU/Socket/SRHM/Script/impute.RData")
macro_impute[1:5,1:5]
macro_impute = complete(imputed_Data, 1)
macro_impute[1:5,1:5]
write.csv(cbind(timestamp = rownames(macro_impute),
macro_impute),
"../Data/macro_impute.csv", row.names = F, quote = F)
macro = read.csv("../Data/macro_impute.csv")
macro_impute[1:5,1:5]
rm(list =ls())
library(caTools)
library(caret)
library(xgboost)
train = read.csv("../Data/train_new.csv", stringsAsFactors = T)
test = read.csv("../Data/test_new.csv", stringsAsFactors = T)
rownames(train) = train$id
rownames(test) = test$id
train = train[,-1]
test = test[,-1]
train_price = train[,ncol(train)]
macro = read.csv("../Data/macro_impute.csv")
macro = read.csv("../Data/macro_impute.csv", row.names = F)
macro = read.table("../Data/macro_impute.csv", row.names = F)
macro = read.table("../Data/macro_impute.csv")
macro[1:5,1:5]
macro = read.table("../Data/macro_impute.csv", sep = ",")
library(preprocessCore)
library(survival)
library(caTools)
library(caret)
library(xgboost)
library(caTools)
library(caret)
library(xgboost)
apply(total_factors,2,function(x) (length(unique(x))))
train = read.csv("../Data/train.csv")
test = read.csv("../Data/test.csv")
hist(log2(train$price_doc))
sm_train = summary(train)
price_log2 = log2(train$price_doc)
q1 = quantile(price_log2, .25)
q3 = quantile(price_log2, .75)
high = q3 + (q3-q1)*5
low = q1 - (q3-q1)*5
price_log2[price_log2 > high] = high
price_log2[price_log2 < low] = low
hist(log2(train$price_doc))
library(lubridate)
hist(price_log2)
total = rbind(train[,-ncol(train)], test)
total[which(total$life_sq > total$full_sq),"life_sq"] = NA
total[which(total$life_sq < 5),"life_sq"] = NA
total[which(total$full_sq < 5),"full_sq"] = NA
total[which(total$kitch_sq < 3),"kitch_sq"] = NA
total[which(total$full_sq > 1000), "full_sq"] = 53.26
total[which(total$full_sq > 150 & total$life_sq /total$full_sq < 0.3), "full_sq"] = NA
total[which(total$build_year > 2020), "build_year"] = NA
total[which(total$build_year < 1600), "build_year"] = NA
total[which(total$num_room == 0), "num_room"] = NA
total[which(total$floor == 0), "floor"] = NA
total[which(total$floor> total$max_floor), "max_floor"] = NA
total[which(total$state == 33), "state"] = NA
total$timestamp = as.Date(as.character(total$timestamp))
total$dayofyear =yday(total$timestamp)
total$dayofmonth =day(total$timestamp)
total$dayofweek = weekdays(total$timestamp)
total$weekofyear = week(total$timestamp)
total$month = months(total$timestamp)
total$rel_floor = total$floor / total$max_floor
total$rel_kitch_sq = total$kitch_sq / total$full_sq
total$rel_life_sq = total$life_sq / total$full_sq
total$name = paste(total$sub_area, total$metro_km_avto)
total$avg_room_sq = total$full_sq / total$num_room
train_new = total[1:nrow(train),]
train_new = cbind(train_new, 2^price_log2)
test_new = total[(nrow(train)+1):nrow(total),]
write.csv(train_new, "../Data/train_new.csv", row.names = F, quote = F)
write.csv(test_new, "../Data/test_new.csv", row.names = F, quote = F)
library(caTools)
library(caret)
library(xgboost)
train = read.csv("../Data/train_new.csv", stringsAsFactors = T)
test = read.csv("../Data/test_new.csv", stringsAsFactors = T)
rownames(train) = train$id
rownames(test) = test$id
train = train[,-1]
test = test[,-1]
train_price = train[,ncol(train)]
macro = read.csv("../Data/macro_impute.csv")
total = rbind(train[,-ncol(train)], test)
total = merge(total, macro, by = "timestamp")
total = total[,-1]
colTypes = sapply(1:ncol(total), function(i) class(total[,i]))
total_factors = total[, colTypes == "factor"]
for(i in 1:ncol(total_factors)) {
t = as.character(total_factors[,i], levels = unique(total_factors[,i]))
t[is.na(t)] = "NA"
total_factors[,i] = factor(t, levels = unique(t))
}
len_factor = apply(total_factors, 2, function(x) length(unique(x)))
len_factor
total_factors$name =NULL
total_dummy = model.matrix(~0+., total_factors)
dim(total_dummy)
train = total[1:nrow(train), colTypes != "factor"]
train = cbind(train, total_dummy[1:nrow(train),])
train = cbind(train, price_doc = train_price)
test = total[-c(1:nrow(train)), colTypes != "factor"]
test = cbind(test, total_dummy[-c(1:nrow(train)),])
rm(total)
rm(total_dummy)
rm(total_factors)
rm(macro)
set.seed(88)
split = sample.split(train$price_doc, SplitRatio = 0.7)
datTest = train[!split,]
datTrain = train[split,]
ef = function(pred, real) {
pred[is.na(pred)] = mean(real)
pred[pred < 0] = min(real)
return(sqrt(sum((log(pred+1) - log(real + 1))^2)/length(pred)))
}
model1 = xgboost(data = as.matrix(datTrain[,-ncol(datTrain)]),
label = datTrain[,ncol(datTrain)],
objective = "reg:linear",
eval_metric = "rmse", max_depth = 6, eta = 0.3,
nthread = 8, nrounds = 1000, subsample = 0.7, colsample_bytree = 0.7)
ef(predict(model1,  as.matrix(datTest)),  datTest$price_doc)
pred = predict(model1, as.matrix(test))
summary(pred)
summary(train$price_doc)
pred[pred < min(train$price_doc)] = min(train$price_doc)
write.csv(cbind(id = rownames(test),
price_doc = pred),
"impute_clean_xgboost_eval.csv", row.names = F)
dim(train)
dim(test)
dim(read.csv("../Data/train.csv"))
dim(read.csv("../Data/test.csv"))
summary(rownames(test))
head(rownames(test))
tail(rownames(test))
anyDuplicated(rownames(test))
head(read.csv("../Data/test.csv")$id)
tail(read.csv("../Data/test.csv")$id)
tail(read.csv("../Data/test_new.csv")$id)
train = read.csv("../Data/train_new.csv", stringsAsFactors = T)
test = read.csv("../Data/test_new.csv", stringsAsFactors = T)
rownames(train) = train$id
rownames(test) = test$id
train = train[,-1]
test = test[,-1]
train_price = train[,ncol(train)]
macro = read.csv("../Data/macro_impute.csv")
total = rbind(train[,-ncol(train)], test)
total = merge(total, macro, by = "timestamp")
total = total[,-1]
colTypes = sapply(1:ncol(total), function(i) class(total[,i]))
total_factors = total[, colTypes == "factor"]
for(i in 1:ncol(total_factors)) {
t = as.character(total_factors[,i], levels = unique(total_factors[,i]))
t[is.na(t)] = "NA"
total_factors[,i] = factor(t, levels = unique(t))
}
len_factor = apply(total_factors, 2, function(x) length(unique(x)))
total_factors$name =NULL
total_dummy = model.matrix(~0+., total_factors)
train = total[1:nrow(train), colTypes != "factor"]
train = cbind(train, total_dummy[1:nrow(train),])
train = cbind(train, price_doc = train_price)
test = total[-c(1:nrow(train)), colTypes != "factor"]
test = cbind(test, total_dummy[-c(1:nrow(train)),])
tail(rownames(test))
tail(rownames(total))
train = read.csv("../Data/train_new.csv", stringsAsFactors = T)
test = read.csv("../Data/test_new.csv", stringsAsFactors = T)
rownames(train) = train$id
rownames(test) = test$id
train = train[,-1]
test = test[,-1]
tail(rownames(test))
macro = read.csv("../Data/macro_impute.csv")
total = rbind(train[,-ncol(train)], test)
total = merge(total, macro, by = "timestamp")
total = total[,-1]
train_price = train[,ncol(train)]
tail(rownames(total))
dim(total)
dim(train)
dim(test)
nrow(test) + nrow(train)
tail(rownames(train))
head(rownames(test))
rownames(total)[1:nrow(train)] = rownames(train)
anyDuplicated(rownames(train))
length(rownames(train))
nrow(train)
rownames(total) = c(rownames(train), rownames(test))
trainId = rownames(train)
testId = rownames(test)
colTypes = sapply(1:ncol(total), function(i) class(total[,i]))
total_factors = total[, colTypes == "factor"]
for(i in 1:ncol(total_factors)) {
t = as.character(total_factors[,i], levels = unique(total_factors[,i]))
t[is.na(t)] = "NA"
total_factors[,i] = factor(t, levels = unique(t))
}
len_factor = apply(total_factors, 2, function(x) length(unique(x)))
total_factors$name =NULL
total_dummy = model.matrix(~0+., total_factors)
train = total[1:nrow(train), colTypes != "factor"]
train = total[trainId, colTypes != "factor"]
train = cbind(train, total_dummy[trainId,])
train = cbind(train, price_doc = train_price)
test = total[testId, colTypes != "factor"]
test = cbind(test, total_dummy[testId,])
tail(rownames(test))
rm(total)
rm(total_dummy)
rm(total_factors)
rm(macro)
set.seed(88)
split = sample.split(train$price_doc, SplitRatio = 0.7)
datTest = train[!split,]
datTrain = train[split,]
ef = function(pred, real) {
pred[is.na(pred)] = mean(real)
pred[pred < 0] = min(real)
return(sqrt(sum((log(pred+1) - log(real + 1))^2)/length(pred)))
}
model1 = xgboost(data = as.matrix(datTrain[,-ncol(datTrain)]),
label = datTrain[,ncol(datTrain)],
objective = "reg:linear",
eval_metric = "rmse", max_depth = 6, eta = 0.3,
nthread = 8, nrounds = 1000, subsample = 0.7, colsample_bytree = 0.7)
# pred <- predict(model, dtest)
ef(predict(model1,  as.matrix(datTest)),  datTest$price_doc)
pred = predict(model1, as.matrix(test))
pred[pred < min(train$price_doc)] = min(train$price_doc)
write.csv(cbind(id = rownames(test),
price_doc = pred),
"impute_clean_xgboost_eval.csv", row.names = F)
lc = as.data.frame(matrix(0, nrow = 10, ncol = 3))
colnames(lc) = c("size", "TrainRMSE", "TestRMSE")
lc$size = ceiling(2.732^(1:10))
set.seed(5354)
rand_ind = sample(1:nrow(datTrain), nrow(datTrain))
for(i in 1:nrow(lc)) {
temptrain = datTrain[rand_ind[1:lc[i,1]],]
lcm = xgboost(data = as.matrix(temptrain[,-ncol(temptrain)]),
label = temptrain[,ncol(temptrain)],
objective = "reg:linear", silent = 1, nthread = 8,
eval_metric = "rmse", nrounds = 2000, max_depth = 5,
eta = 0.02, gamma = 0.1, colsample_bytree = 1,
min_child_weight = 1, subsample = 0.7)
lc[i,2] = ef(predict(lcm, as.matrix(temptrain)),  temptrain$price_doc)
lc[i,3] = ef(predict(lcm, as.matrix(datTest)),  datTest$price_doc)
}
lc = as.data.frame(matrix(0, nrow = 10, ncol = 3))
colnames(lc) = c("size", "TrainRMSE", "TestRMSE")
lc$size = ceiling(2.732^(1:10))
set.seed(5354)
rand_ind = sample(1:nrow(datTrain), nrow(datTrain))
for(i in 1:nrow(lc)) {
temptrain = datTrain[rand_ind[1:lc[i,1]],]
lcm = xgboost(data = as.matrix(temptrain[,-ncol(temptrain)]),
label = temptrain[,ncol(temptrain)],
objective = "reg:linear", silent = 1, nthread = 8,
eval_metric = "rmse", nrounds = 500, max_depth = 5,
eta = 0.02, gamma = 0.1, colsample_bytree = 1,
min_child_weight = 1, subsample = 0.7)
lc[i,2] = ef(predict(lcm, as.matrix(temptrain)),  temptrain$price_doc)
lc[i,3] = ef(predict(lcm, as.matrix(datTest)),  datTest$price_doc)
}
ggplot(lc) +
geom_line(aes(x = size, y = TrainRMSE), color = "red") +
geom_line(aes(x = size, y = TestRMSE), color = "blue") +
geom_hline(yintercept = 0.32, color = "black")
xgb_grid_1 = expand.grid(
nrounds = 1000,
eta = c(0.01, 0.02, 0.05),
max_depth = c(4, 5, 6),
gamma = c(3, 1, 0.3, 0.1),
colsample_bytree = c(0.75, 1),
min_child_weight = c(1,5),
subsample = c(0.7, 0.8)
)
xgb_trcontrol_1 = trainControl(
method = "cv",
number = 3,
verboseIter = TRUE,
returnData = FALSE,
returnResamp = "all",                   # save losses across all models
classProbs = TRUE,                      # set to TRUE for AUC to be computed
allowParallel = TRUE
)
xgb_train_1 = train(
x = datTrain[,-ncol(datTrain)],
y = datTrain[,ncol(datTrain)],
trControl = xgb_trcontrol_1,
tuneGrid = xgb_grid_1,
method = "xgbTree",
eval_metric = "rmse",
objective = "reg:linear",
silent = 1,
nthread = 8
)
warnings()
head(xgb_train_1$results[order(xgb_train_1$results$RMSE),])
ef(predict(model1,  as.matrix(datTest)),  datTest$price_doc)
model2 = xgboost(data = as.matrix(datTrain[,-ncol(datTrain)]),
label = datTrain[,ncol(datTrain)],
objective = "reg:linear",
eval_metric = "rmse", nrounds = 1000, max_depth = 5,
eta = 0.02, gamma = 0.3,
colsample_bytree = 1, min_child_weight = 1,
subsample = 0.8)
model2 = xgboost(data = as.matrix(datTrain[,-ncol(datTrain)]),
label = datTrain[,ncol(datTrain)],
objective = "reg:linear", nthread = 8,
eval_metric = "rmse", nrounds = 1000, max_depth = 5,
eta = 0.02, gamma = 0.3,
colsample_bytree = 1, min_child_weight = 1,
subsample = 0.8)
ef(predict(model2,  as.matrix(datTest)),  datTest$price_doc)
pred2 = predict(model2, as.matrix(test))
summary(pred2)
write.csv(cbind(id = rownames(test),
price_doc = pred2),
"impute_clean_tune_xgboost_eval.csv", row.names = F)
head(xgb_train_1$results[order(xgb_train_1$results$RMSE),], 10)
dim(xgb_grid_1)
dim(expand.grid(
nrounds = 1000,
eta = c(0.015, 0.02, 0.025),
max_depth = c(4, 5, 6),
gamma = c(3, 1, 0.3),
colsample_bytree = c(0.75,0.85, 1),
min_child_weight = c(1,2,5),
subsample = c(0.6, 0.7, 0.8)
))
xgb_train_1
xgb_grid_1 = expand.grid(
nrounds = 1000,
eta = c(0.015, 0.02, 0.025),
max_depth = c(4, 5, 6),
gamma = c(3, 1, 0.3),
colsample_bytree = c(0.75,0.85, 1),
min_child_weight = c(1, 2, 5),
subsample = c(0.6, 0.7, 0.8)
)
xgb_trcontrol_1 = trainControl(
method = "cv",
number = 3,
verboseIter = TRUE,
returnData = FALSE,
returnResamp = "all",                   # save losses across all models
classProbs = TRUE,                      # set to TRUE for AUC to be computed
allowParallel = TRUE
)
xgb_train_1 = train(
x = datTrain[,-ncol(datTrain)],
y = datTrain[,ncol(datTrain)],
trControl = xgb_trcontrol_1,
tuneGrid = xgb_grid_1,
method = "xgbTree",
eval_metric = "rmse",
objective = "reg:linear",
silent = 1,
nthread = 8
)
save.image("./impute_clean_xgboost.RData")
head(xgb_train_1$results[order(xgb_train_1$results$RMSE),])
model2 = xgboost(data = as.matrix(datTrain[,-ncol(datTrain)]),
label = datTrain[,ncol(datTrain)],
objective = "reg:linear", nthread = 8,
eval_metric = "rmse", nrounds = 1000, max_depth = 5,
eta = 0.025, gamma = 0.3, colsample_bytree = 0.85,
min_child_weight = 1, subsample = 0.88)
ef(predict(model2,  as.matrix(datTest)),  datTest$price_doc)
pred2 = predict(model2, as.matrix(test))
summary(pred2)
write.csv(cbind(id = rownames(test),
price_doc = pred2),
"impute_clean_tune_xgboost_eval.csv", row.names = F)
save.image("./impute_clean_xgboost.RData")
library(doSNOW)
library(foreach)
library(caTools)
# library(caret)
# library(FNN)
# library(KernelKnn)
# library(e1071)
library(doSNOW)
library(foreach)
train = read.csv("../Data/train_new.csv", stringsAsFactors = T)
test = read.csv("../Data/test_new.csv", stringsAsFactors = T)
rownames(train) = train$id
rownames(test) = test$id
train = train[,-1]
test = test[,-1]
train_price = train[,ncol(train)]
macro = read.csv("../Data/macro_impute.csv")
total = rbind(train[,-ncol(train)], test)
total = merge(total, macro, by = "timestamp")
total = total[,-1]
rownames(total) = c(rownames(train), rownames(test))
trainId = rownames(train)
testId = rownames(test)
colTypes = sapply(1:ncol(total), function(i) class(total[,i]))
total_factors = total[, colTypes == "factor"]
for(i in 1:ncol(total_factors)) {
t = as.character(total_factors[,i], levels = unique(total_factors[,i]))
t[is.na(t)] = "NA"
total_factors[,i] = factor(t, levels = unique(t))
}
len_factor = apply(total_factors, 2, function(x) length(unique(x)))
total_factors$name =NULL
total_dummy = model.matrix(~0+., total_factors)
train = total[trainId, colTypes != "factor"]
# col_na = apply(train, 2, anyNA)
# na_mean = colMeans(train[,col_na], na.rm = T)
for(i in 1:ncol(train)) {
na_row = is.na(train[,i])
if(sum(na_row) > 0) {
train[na_row, i] = mean(train[,i], na.rm = T)
}
}
train = cbind(train, total_dummy[trainId,])
train = cbind(train, price_doc = train_price)
test = total[testId, colTypes != "factor"]
for(i in 1:ncol(test)) {
na_row = is.na(test[,i])
if(sum(na_row) > 0) {
test[na_row, i] = mean(train[,i], na.rm = T)
}
}
test = cbind(test, total_dummy[testId,])
stopifnot(!(anyNA(test) | anyNA(train)))
# rm(total)
# rm(total_dummy)
# rm(total_factors)
# rm(macro)
set.seed(88)
split = sample.split(train$price_doc, SplitRatio = 0.7)
datTest = train[!split,]
datTrain = train[split,]
cl = makeCluster(6)
registerDoSNOW(cl)
dim(datTrain)
set.seed(847)
split1 = sample.split(datTrain$price_doc, SplitRatio = 0.67)
split2 = sample.split(datTrain$price_doc[!split1], SplitRatio = 0.5)
length(split1)
table(split1)
folds= list()
folds[[1]] = datTrain[!split1,]
folds[[2]] = datTrain[split1,][split2,]
folds[[3]] = datTrain[split1,][!split2,]
ef = function(pred, real) {
pred[is.na(pred)] = mean(real)
pred[pred < 0] = min(real)
return(sqrt(sum((log(pred+1) - log(real + 1))^2)/length(pred)))
}
mean(3,4,5)
mean(c(3,4,5))
cv_res = foreach(i=seq(2,20,2), .packages=c('caret'),
.verbose = T, .combine = rbind) %dopar%  {
td = rbind(folds[[1]],folds[[2]])
vd = folds[[3]]
fit = knnreg(x = td[,-ncol(td)], y =  td[,ncol(td)], k = i)
e1 = ef(predict(fit, vd[,-ncol(vd)]), vd[,ncol(vd)])
td = rbind(folds[[1]],folds[[3]])
vd = folds[[2]]
fit = knnreg(x = td[,-ncol(td)], y =  td[,ncol(td)], k = i)
e2 = ef(predict(fit, vd[,-ncol(vd)]), vd[,ncol(vd)])
td = rbind(folds[[3]],folds[[2]])
vd = folds[[1]]
fit = knnreg(x = td[,-ncol(td)], y =  td[,ncol(td)], k = i)
e3 = ef(predict(fit, vd[,-ncol(vd)]), vd[,ncol(vd)])
return(c(i, mean(c(e1,e2,e3))))
}
expand.grid
cv_grid = expand.grid(fold = 1:3,
k = seq(2,20,2))
cv_grid
